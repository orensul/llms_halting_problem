<!DOCTYPE html>
<html>
<head>
  <title> LLMs versus the Halting Problem: Revisiting Program Termination Prediction</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
<style>
  /* ===============================
     HERO LAYOUT
     =============================== */

  .paper-hero {
    padding-top: 2.5rem;
    padding-bottom: 2.5rem;
  }

  /* ===============================
     TITLE
     =============================== */

  .paper-hero .hero-title {
    max-width: 18em;
    margin: 0 auto 0.75rem auto;
    line-height: 1.08;
    letter-spacing: -0.02em;
  }

  /* ===============================
     AUTHORS
     =============================== */

  .paper-hero .publication-authors {
    max-width: 52rem;
    margin-left: auto;
    margin-right: auto;
  }

  .paper-hero .author-block {
    display: inline-block;
    margin: 0.18rem 0.38rem;
    white-space: nowrap;
  }

  .paper-hero .author-block a {
    text-decoration: none;
    border-bottom: 1px solid transparent;
    padding-bottom: 1px;
  }

  /*.paper-hero .author-block a:hover {*/
  /*  border-bottom-color: currentColor;*/
  /*}*/

  /* ===============================
     AFFILIATIONS + LOGOS (logo at END)
     =============================== */

  .paper-hero .affiliations {
    font-size: 0.98rem;
    opacity: 0.95;
    margin-top: 0.9rem;
  }

  /* Each affiliation line is centered as a unit */
  .paper-hero .affiliation-row {
    display: flex;
    justify-content: center;
    margin-top: 0.45rem;
  }

  /* Inner content shrinks to fit, keeps "text ... logo" stable */
  .paper-hero .affiliation-row > span,
  .paper-hero .affiliation-row > img {
    display: inline-block;
  }

  .paper-hero .affiliation-row span {
    margin-right: 0.8rem;
  }

 .paper-hero .affiliation-logo {
  height: 28px;
  width: auto;
  max-width: 120px;
  object-fit: contain;
  display: block;
  opacity: 1;          /* full color */
  filter: none;        /* no grayscale */
}



  /*.paper-hero .affiliation-row:hover .affiliation-logo {*/
  /*  filter: grayscale(0%);*/
  /*  opacity: 1;*/
  /*}*/

  /* ===============================
     PUBLICATION LINKS
     =============================== */

  .paper-hero .publication-links {
    margin-top: 1.2rem;
    display: flex;
    justify-content: center;
    flex-wrap: wrap;
    gap: 0.65rem;
  }

  .paper-hero .publication-links .button {
    padding-left: 1.15rem;
    padding-right: 1.15rem;
    box-shadow: 0 10px 26px rgba(0, 0, 0, 0.14);
    transition: transform 140ms ease, box-shadow 140ms ease;
  }

  /*.paper-hero .publication-links .button:hover {*/
  /*  transform: translateY(-1px);*/
  /*  box-shadow: 0 14px 34px rgba(0, 0, 0, 0.18);*/
  /*}*/

  /* ===============================
     HERO TEASER IMAGE (paper artwork)
     =============================== */

  .paper-hero .hero-teaser {
    margin-top: 2.2rem;
    display: flex;
    justify-content: center;
  }

  .paper-hero .hero-teaser img {
    max-width: 85%;
    height: auto;
    border-radius: 12px;
    box-shadow: 0 18px 40px rgba(0, 0, 0, 0.18);
  }


  /* ===============================
     MOBILE TWEAKS
     =============================== */

  @media (max-width: 768px) {
    .paper-hero {
      padding-top: 2rem;
      padding-bottom: 2rem;
    }

    .paper-hero .hero-title {
      max-width: 22em;
    }

    .paper-hero .author-block {
      margin: 0.12rem 0.28rem;
    }

    .paper-hero .affiliation-logo {
      height: 24px;
      max-width: 110px;
    }

    .paper-hero .hero-teaser img {
      max-width: 95%;
    }

  }
</style>





<section class="hero paper-hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <h1 class="title is-1 publication-title hero-title">
            LLMs versus the Halting Problem:<br>
            Revisiting Program Termination Prediction
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.orensultan.com/" target="_blank" rel="noopener noreferrer">
                Oren Sultan<sup>1, 2</sup>
              </a>,
            </span>

            <span class="author-block">
              <a href="https://jordiae.com/" target="_blank" rel="noopener noreferrer">
                Jordi Armengol-Estap√©<sup>1</sup>
              </a>,
            </span>

            <span class="author-block">
              <a href="https://www.linkedin.com/in/pascal-kesseli-99561b84/" target="_blank" rel="noopener noreferrer">
                Pascal Kesseli<sup>1</sup>
              </a>,
            </span>

            <span class="author-block">
              <a href="https://www.linkedin.com/in/julienvanegue/" target="_blank" rel="noopener noreferrer">
                Julien Vanegue<sup>3</sup>
              </a>,
            </span>

            <span class="author-block">
              <a href="http://www.hyadatalab.com/" target="_blank" rel="noopener noreferrer">
                Dafna Shahaf<sup>2</sup>
              </a>,
            </span>

            <span class="author-block">
  <a href="https://www.cs.huji.ac.il/~adiyoss/" target="_blank" rel="noopener noreferrer">
    Yossi Adi<sup>1*</sup>
  </a>,
</span>

<span class="author-block">
  <a href="http://www0.cs.ucl.ac.uk/staff/p.ohearn/" target="_blank" rel="noopener noreferrer">
    Peter O'Hearn<sup>1*</sup>
  </a>
</span>

          </div>

          <div class="is-size-5 publication-authors affiliations">
            <div class="affiliation-row">
              <span>
  <a href="https://ai.meta.com/research/" target="_blank" rel="noopener noreferrer">
    (1) FAIR Team, Meta AI
  </a>
</span>

              <img class="affiliation-logo" src="static/images/meta.jpeg" alt="Meta AI logo">
            </div>

            <div class="affiliation-row">
              <span>
  <a href="https://en.huji.ac.il/" target="_blank" rel="noopener noreferrer">
    (2) The Hebrew University of Jerusalem
  </a>
</span>

              <img class="affiliation-logo" src="static/images/huji.jpeg" alt="Hebrew University logo">
            </div>

            <div class="affiliation-row">
              <span>
  <a href="https://www.bloomberg.com/company/what-we-do/engineering-cto/"
     target="_blank"
     rel="noopener noreferrer">
    (3) Bloomberg Research
  </a>
</span>

              <img class="affiliation-logo" src="static/images/bloomberg.jpeg" alt="Bloomberg logo">
            </div>
          </div>
        <div class="is-size-6 publication-notes">
  <span>* Joint supervision</span>
</div>

          <div class="publication-links">
            <span class="link-block">
              <a
                href="https://arxiv.org/pdf/2601.18987"
                target="_blank"
                rel="noopener noreferrer"
                class="external-link button is-normal is-rounded is-dark"
              >
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
          </div>

          <!-- ===== Hero Teaser Image ===== -->
          <div class="hero-teaser">
            <img
              src="static/images/LLMsHaltingProblemImage.jpeg"
              alt="Conceptual illustration of the Halting Problem and Large Language Models"
            >
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<!--               <span class="link-block">
                <a href="https://github.com/orensultan/AIRecolor" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span> -->
      <!--         <span class="link-block">
                <a href="https://arxiv.org/pdf/2410.02952" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

     <!--          <span class="link-block">
              <a href="https://www.orensultan.com/files/posters/AIRecolorPoster.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Poster</span>
              </a>
            </span> -->

            <!--   <span class="link-block">
                <a href="https://www.youtube.com/watch?v=wdGOYrtm1Oc" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->


            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>





  <!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Determining whether a program terminates is
a central problem in computer science. Turing‚Äôs foundational result established the Halting
Problem as undecidable, showing that no algorithm can universally determine termination
for all programs and inputs. Consequently,
automatic verification tools approximate termination, sometimes failing to prove or disprove;
these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success
and progress in large language models (LLMs)
raises the following question: can LLMs reliably predict program termination? In this
work, we evaluate LLMs on a diverse set of ùê∂
programs from the Termination category of the
International Competition on Software Verification (SV-Comp) 2025. Our results suggest
that LLMs perform remarkably well at predicting program termination, where GPT-5 and
Claude Sonnet-4.5 would rank just behind the
top-ranked tool (using test-time-scaling), and
Code World Model (CWM) would place just
behind the second-ranked tool. While LLMs
are effective at predicting program termination,
they often fail to provide a valid witness as a
proof. Moreover, LLMs performance drops
as program length increases. We hope these
insights motivate further research into program
termination and the broader potential of LLMs
for reasoning about undecidable problems.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->




  <!-- Teaser video -->
  <section class="hero teaser" style="margin-top: 50px;">
  <div class="container is-max-desktop" style="display: flex; justify-content: center; align-items: center; height: 100vh; flex-direction: column; text-align: center;">
    <h2 class="title is-3">AI Podcast üéôü§ñÔ∏è</h2>
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop style="width: 60%; height: 400px;">
        <!-- Your video here -->
        <source src="static/videos/LLMs_vs_Halting_Problem.mp4" type="video/mp4">
      </video>
      <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
  <b>Termination prediction task.</b><br>
  Given a program, the task is to predict whether the program halts for all inputs
  (instantiations of nondeterministic variables).<br>
  (1)
  Traditional verification tools such as <span style="font-variant: small-caps;">PROTON</span>
  rely on multi-component architectures for parsing, input augmentation, and tool-chain management
  (2)
  We investigate whether large language models (LLMs) can match state-of-the-art verification tools,
  offering a simpler, language-agnostic solution, as illustrated in the example above where the LLM
  correctly predicts termination.
</p>

    </div>
  </div>
</section>

  <!-- End teaser video -->





<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop"
         style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">
      <h2 class="title is-3">Non-termination witness prediction</h2>
      <img src="static/images/witness_example.jpeg"
           alt="Website"
           style="max-width: 80%; height: auto; margin-bottom: 30px;">

      <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
        Given a <i>C</i> program, an LLM that predicts <i>nontermination</i> must additionally output
        a witness automaton as a proof in JSON format.
        The witness automaton models a potentially infinite execution:
        nodes correspond to program states, and edges correspond to transitions.<br>

        The predicted JSON is converted to
        <span style="font-variant: small-caps;">GraphML</span>
        and validated using a witness validator (e.g.,
        <span style="font-variant: small-caps;">UAutomizer</span>).
        The example illustrates a loop in which the variable
        <i>i</i> is initialized in the range
        [‚àí5, 5], eventually reaches 0 (as specified by the assumption on edge E2),
        and then executes indefinitely.
      </p>

    </div>
  </div>
</section>




<section class="image-section" style="margin-top: 100px;"> <!-- Adjusted margin-top -->
  <div class="container is-max-desktop" style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">
    <h2 class="title is-3">SV-Comp Dataset</h2>
    <img src="static/images/svcomp_dataset.jpeg" alt="Website" style="max-width: 80%; height: auto; margin-bottom: 30px;"> <!-- Increased margin-bottom -->
    <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
      We evaluate on <span style="font-variant: small-caps;">SV-Comp&nbsp;2025</span>, the largest public verification benchmark, focusing on the termination category (2,328 <i> C </i> programs) spanning bit-precise arithmetic, complex control flow, heap manipulation, and real-world code.
</p>
  </div>
</section>




<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop"
         style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">
          <h2 class="title is-3">SV-Comp Scoring</h2>
      <img src="static/images/svcomp_scoring.jpeg"
           alt="Website"
           style="max-width: 80%; height: auto; margin-bottom: 30px;">
      <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
  We adopt <span style="font-variant: small-caps;">SV-Comp's</span> asymmetric scoring, treating non-termination (NT) as the positive class.
  Correct termination predictions (true negatives, TN) receive +2 points.
  Correct non-termination predictions receive +1 point when accompanied by a valid witness (TP<sub>valid&nbsp;witness</sub>),
  and 0 points when the witness is invalid (TP<sub>invalid&nbsp;witness</sub>) or the prediction is marked as unknown.
  Incorrect non-termination predictions (false positives, FP) are penalized with ‚àí16 points,
  while incorrect termination predictions (false negatives, FN) incur a ‚àí32 point penalty.
  This asymmetric scheme reflects a safety-first priority: misclassifying a non-terminating program as terminating is far more harmful than unnecessary conservatism.
</p>


    </div>
  </div>
</section>





<!-- Image Section for "Our Distillation Framework" -->
<section class="image-section" style="margin-top: 100px;"> <!-- Adjusted margin-top -->
  <div class="container is-max-desktop" style="display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; padding: 20px;">
    <h2 class="title is-3">SV-Comp main results</h2>
    <img src="static/images/main_results.jpeg" alt="Website" style="max-width: 80%; height: auto; margin-bottom: 30px;"> <!-- Increased margin-bottom -->
    <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
  Mean <span style="font-variant: small-caps;">SV-Comp</span> scores for LLMs
  (averaged over 100 bootstrap samples), the top
  <span style="font-variant: small-caps;">SV-Comp&nbsp;2025</span> verification tools,
  and the maximum achievable score
  (minimum possible score: ‚àí50,064).
  <span style="font-variant: small-caps;">GPT-5</span> with test-time scaling (TTS)
  and <span style="font-variant: small-caps;">Claude&nbsp;Sonnet-4.5</span> (TTS)
  would rank 2nd and 3rd with scores of 3,520 and 3,448, respectively,
  trailing the gold-medal system
  <span style="font-variant: small-caps;">PROTON</span>.
  <span style="font-variant: small-caps;">CWM</span> ranks just below
  <span style="font-variant: small-caps;">UAutomizer</span>.
  In contrast, <span style="font-variant: small-caps;">GPT-4o</span>
  performs substantially worse, scoring 546 with TTS and ‚àí5,145 without TTS.
      <b>* Test-time scaling (TTS) uses consensus voting: for each instance, we sample 10 of 20 predictions and output the label only if all agree (ignoring "unknown"); otherwise, we predict "unknown" to reflect uncertainty and avoid risky errors.</b>

</p>

  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small" style="margin-top: 150px;">
  <div class="hero-body" style="display: flex; justify-content: center; align-items: center;">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" style="display: flex; justify-content: center; align-items: center;">

        <div class="item" style="text-align: center;">
          <h2 class="title is-4">SV-Comp F1 Scores</h2>
          <img src="static/images/llm_f1_score.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
            LLMs F1 scores per class. F1 (T) and F1 (NT)
are averaged over 100 bootstrap runs. F1 decreases under
TTS due to increased unknown predictions (counted as
errors in F1). Rankings align with SV-Comp score.
          </p>
        </div>

        <div class="item" style="text-align: center;">
          <h2 class="title is-4">Witness Prediction Accuracy</h2>
          <img src="static/images/llm_witness_prediction.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
            LLMs witness prediction (validated by UAutomizer) success rates. Metrics: P (Precision): (%)
of validated witness NT predictions out of all NT predictions; R (Recall): (%) of validated witness NT predictions out of all NT samples; V (Validity): (%) of
validated witness NT predictions out of all correct NT
predictions. GPT-5 and Claude lead in prediction rates,
while CWM, GPT-4o, and Qwen3-32B perform lower,
highlighting the challenge of generating a valid witness.
          </p>
        </div>

        <div class="item" style="text-align: center;">
          <h2 class="title is-4">Unknown Prediction Rates</h2>
          <img src="static/images/llm_unk_prediction.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
             LLMs unknown prediction distribution. Unk:
(%) of unknown predictions, aggregated over 20 generations per entry. TTS-Unk: (%) of cases without
unanimous agreement among 10 model predictions, resulting in an unknown. As we can see, GPT-5 and Claude
Sonnet-4.5 rarely predict unknown, while GPT-4o does
so most often. For TTS-Unk, GPT-5 and Claude show
high prediction unanimity, whereas CWM, Qwen3-32B,
and GPT-4o have more disagreement ‚Äì improving SVComp scores but lowers F1 scores.
          </p>
        </div>

        <div class="item" style="text-align: center;">
          <h2 class="title is-4">Performance vs. Code Length</h2>
          <img src="static/images/code_length_bins.jpeg" style="max-width: 80%; height: auto; margin-bottom: 15px;">
          <p class="subtitle" style="text-align: left; max-width: 80%; margin: 20px auto 0;">
            LLMs mean SV-Comp score vs. code
length. Dataset examples are grouped into three equal
size bins by code length (measured in tokens using
Instruct Llama3 Tokenizer) (x axis). The mean SVComp score (y axis) per bin is shown for all models
(20 predictions per sample). Scores decrease with code
length; GPT-5 leads, followed by Claude and CWM.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->




<!--  &lt;!&ndash; Youtube video &ndash;&gt;-->
<!--  <section class="hero is-small is-light" style="margin-top: 100px;">-->
<!--    <div class="hero-body">-->
<!--      <div class="container">-->
<!--        <h2 class="title is-3">Lightricks Real Use-case: Visual Editing with LLM-based Tool Chaining</h2>-->
<!--        <div class="columns is-centered has-text-centered">-->
<!--          <div class="column is-four-fifths">-->
<!--            <div class="publication-video">-->
<!--              <iframe src="https://www.youtube.com/embed/XWM7MM4M2Ws" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--            </div>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--  &lt;!&ndash; End youtube video &ndash;&gt;-->

 <!--  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">EMNLP 2024 Poster</h2>
        <iframe src="static/pdfs/AIRecolorPoster.pdf" width="100%" height="550"></iframe>
      </div>
    </div>
  </section> -->

  <!-- BibTex citation -->
  <section class="section" id="BibTeX" style="margin-top: 100px;">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sultan2026llms_vs_halting_problem,
  title={LLMs versus the Halting Problem: Revisiting Program Termination Prediction},
  author={Sultan, Oren and Armengol-Estap√©, Jordi and Kesseli, Pascal and Vanegue, Julien and Shahaf, Dafna and Adi, Yossi and O'Hearn Peter},
  journal={arXiv preprint arXiv:2601.18987},
  year={2026}
}</code></pre>
  </div>
</section>

  <!-- End BibTeX citation -->

<!--  <footer class="footer">-->
<!--    <div class="container">-->
<!--      <div class="columns is-centered">-->
<!--        <div class="column is-8">-->
<!--          <div class="content">-->
<!--            <p>-->
<!--              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.-->
<!--              <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative-->
<!--              Commons Attribution-ShareAlike 4.0 International License</a>.-->
<!--            </p>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </footer>-->

  <!-- Statcounter tracking code -->
  <script type="text/javascript">
  var sc_project=12822541;
  var sc_invisible=1;
  var sc_security="46936e0e";
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img class="statcounter"
  src="https://c.statcounter.com/12822541/0/46936e0e/1/" alt="Web Analytics"
  referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
  <!-- End of Statcounter Code -->

</body>
</html>
